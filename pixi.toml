[workspace]
authors = ["VioletsOleander <1377232072@qq.com>"]
channels = ["conda-forge"]
name = "mnist"
platforms = ["linux-64"]
version = "0.1.0"

[tasks]

[tasks.configure]
args = [{ arg = "build_type", default = "debug" }]
cmd = "cmake --preset={{ build_type }} -B build"
description = "Configure the project using CMake"
inputs = [
  "CMakeLists.txt",
  "src/CMakeLists.txt",
  "src/bin/CMakeLists.txt",
  "src/lib/CMakeLists.txt",
]
outputs = ["build/build.ninja"]

[tasks.build]
cmd = "cmake --build build"
description = "Build the project with generated configuration files"

[tasks.train]
args = [{ arg = "config", default = "configs/train.toml" }]
cmd = "./build/bin/mnist_train {{ config }}"
description = "Run the MNIST training executable"
inputs = ["build/bin/mnist_train", "{{ config }}"]
outputs = ["checkpoints/mnist_model.pt"]

[tasks.test]
args = [{ arg = "config", default = "configs/test.toml" }]
cmd = "./build/bin/mnist_test {{ config }}"
description = "Run the MNIST testing executable"
inputs = ["build/bin/mnist_test", "{{ config }}"]

[dependencies]
libtorch = { version = ">=2.8.0,<3", build = "*cpu*" }
cmake = ">=4.1.2,<5"
ninja = ">=1.13.1,<2"
clangxx = ">=21.1.2,<22"
lld = ">=21.1.3,<22"
libcxx-devel = ">=21.1.3,<22"
tomlplusplus = ">=3.3.0,<4"
cli11 = ">=2.5.0,<3"

[feature.dataset.dependencies]
python = "*"

[feature.dataset.pypi-dependencies]
huggingface-hub = { version = ">=0.35.3, <0.36", extras = ["cli"] }
datasets = ">=4.2.0, <5"
pillow = ">=11.3.0, <12"

[feature.dataset.tasks]

[feature.dataset.tasks.hf-login]
cmd = "hf auth login --token $HF_TOKEN"
description = "Log in to Hugging Face using the provided token"

[feature.dataset.tasks.get-dataset]
cmd = "hf download --repo-type dataset --local-dir dataset/raw ylecun/mnist"
description = "Download the MNIST dataset from Hugging Face"
outputs = [
  "dataset/raw/mnist/*.parquet",
  "dataset/raw/.gitattributes",
  "dataset/raw/README.md",
]

[feature.dataset.tasks.process-dataset]
cmd = "python scripts/preprocess.py"
description = "Converts the Parquet dataset to raw binary images and text labels."
depends-on = ["get-dataset"]
inputs = ["scripts/preprocess.py"]
outputs = [
  "dataset/processed/test/images.bin",
  "dataset/processed/train/labels.bin",
  "dataset/processed/train/images.bin",
  "dataset/processed/test/labels.bin",
]

[environments]
dataset = { features = ["dataset"], no-default-feature = true }
